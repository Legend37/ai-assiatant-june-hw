import gradio as gr
import os
from chat import chat  
from pdf import read_file_content
from image_generate import image_generate
from mnist import image_classification  # å¯¼å…¥å›¾ç‰‡åˆ†ç±»å‡½æ•°
from search import search
from fetch import fetch 
messages = [] 
current_file_text = None
current_file_type = None

def write_debug_info(messages, history):
    """Write the current messages and history to answer/answer.txt for debugging purposes"""
    # Create answer directory if it doesn't exist
    os.makedirs('answer', exist_ok=True)
    
    with open('answer/answer.txt', 'a', encoding='utf-8') as f:
        f.write("\n----- Messages -----\n")
        for i, message in enumerate(messages):
            f.write(f"[{i}] {message['role']}: {message['content'][:50]}{'...' if len(message['content']) > 50 else ''}\n")
        
        f.write("\n----- History -----\n")
        for i, (user, assistant) in enumerate(history):
            # User content could be either text or file tuple
            if isinstance(user, tuple):
                user_content = f"File: {user[0]}"
            else:
                user_content = user[:50] + ('...' if len(user) > 50 else '')
            
            # Assistant content could be None, text, or image tuple
            if assistant is None:
                assistant_content = "None"
            elif isinstance(assistant, tuple) and len(assistant) == 1:
                assistant_content = f"Image: {assistant[0][:40]}..."
            else:
                assistant_content = str(assistant)[:50] + ('...' if len(str(assistant)) > 50 else '')
                
            f.write(f"[{i}] user: {user_content}\n")
            f.write(f"    assistant: {assistant_content}\n\n")
        
        f.write("-" * 50 + "\n")

def add_text(history, text):
    """Process user input text, update chat history and message list"""
    global messages
    
    history = history + [(text, None)]
    
    messages.append({"role": "user", "content": text})
    return history, gr.update(value="", interactive=False)  # Clear textbox and disable interaction

def add_file(history, file):
    global messages, current_file_text, current_file_type
    
    try:
        file_path = file.name
        filename = os.path.basename(file_path)
        file_ext = os.path.splitext(filename)[1].lower()
        current_file_type = file_ext

        # å¤„ç†PNGå›¾ç‰‡
        if file_ext == '.png':
            messages.append({"role": "user", "content": f"Please classify {filename}"})
            history = history + [((file.name,), None)]
            return history
        
        # å¤„ç†æ–‡æœ¬/PDFæ–‡ä»¶
        current_file_text = read_file_content(file_path)
        if current_file_text:
            # æ·»åŠ æ–‡ä»¶ä¿¡æ¯åˆ°æ¶ˆæ¯è®°å½•
            file_info = f"Uploaded file: {filename} ({file_ext} format)"
            messages.append({"role": "user", "content": file_info})
            history = history + [((file.name,), None)]
            
            # å¦‚æœæ˜¯TXTæ–‡ä»¶ï¼Œè‡ªåŠ¨è§¦å‘æ€»ç»“
            if file_ext == '.txt':
                summary_request = "Please summarize the uploaded document"
                messages.append({"role": "user", "content": summary_request})
                history = history + [(summary_request, None)]
        else:
            # æ–‡ä»¶å†…å®¹è¯»å–å¤±è´¥
            error_msg = f"æ— æ³•è¯»å–æ–‡ä»¶å†…å®¹: {filename}"
            messages.append({"role": "user", "content": error_msg})
            history = history + [(error_msg, None)]
    
    except Exception as e:
        error_msg = f"æ–‡ä»¶å¤„ç†é”™è¯¯: {str(e)}"
        messages.append({"role": "user", "content": error_msg})
        history = history + [(error_msg, None)]
    
    return history
def bot(history):
    """Call the model to generate a reply and update chat history"""
    global messages, current_file_text, current_file_type

    # é™åˆ¶æ¶ˆæ¯å†å²é•¿åº¦ï¼Œé¿å…è¶…è¿‡ä¸Šä¸‹æ–‡çª—å£
    def trim_messages(messages, max_messages=10):
        """ä¿ç•™æœ€è¿‘çš„æ¶ˆæ¯ï¼Œé¿å…ä¸Šä¸‹æ–‡è¿‡é•¿"""
        if len(messages) <= max_messages:
            return messages
        # ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯ï¼ˆå¦‚æœæœ‰ï¼‰å’Œæœ€è¿‘çš„æ¶ˆæ¯
        system_messages = [msg for msg in messages if msg.get("role") == "system"]
        recent_messages = messages[-max_messages:]
        return system_messages + recent_messages

    last_message = messages[-1]["content"]
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯åˆ†ç±»å›¾ç‰‡è¯·æ±‚ï¼ˆæ ¼å¼ä¸º"Please classify {filename}"ï¼‰
    if last_message.startswith("Please classify ") and ".png" in last_message:
        # ä»æœ€åä¸€ä¸ªhistoryæ¡ç›®ä¸­è·å–æ–‡ä»¶è·¯å¾„
        if len(history) > 0 and isinstance(history[-1][0], tuple) and len(history[-1][0]) > 0:
            file_path = history[-1][0][0]  # è·å–æ–‡ä»¶è·¯å¾„

            classification_result = image_classification(file_path)
            messages.append({"role": "assistant", "content": classification_result})
            history[-1][1] = classification_result
            
            write_debug_info(messages, history)
            yield history
        
    # æ£€æŸ¥æ˜¯å¦æ˜¯å›¾ç‰‡ç”ŸæˆæŒ‡ä»¤
    elif last_message.startswith("/image "):

        image_content = last_message[7:]  # ç§»é™¤"/image "å‰ç¼€

        image_url = image_generate(image_content)
        messages.append({"role": "assistant", "content": image_url or ""})

        # å°†URLè½¬æ¢ä¸ºæœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼Œé¿å…SSRFé—®é¢˜
        def url_to_local_path(url):
            if not url:
                return ""
            # å…ˆç§»é™¤URLå‰ç¼€
            if url.startswith("http://localhost:8080/"):
                relative_path = url.replace("http://localhost:8080/", "")
            elif url.startswith("http://127.0.0.1:8080/"):
                relative_path = url.replace("http://127.0.0.1:8080/", "")
            else:
                relative_path = url
            
            # å°†generated-imagesè·¯å¾„æ˜ å°„åˆ°LocalAIç›®å½•
            relative_path = relative_path.replace("generated-images", "LocalAI/generated/images")
            return relative_path

        # åˆ¤æ–­è¿”å›çš„æ˜¯URLè¿˜æ˜¯é”™è¯¯ä¿¡æ¯
        if not image_url or image_url.startswith("å›¾ç‰‡ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™"):
            history[-1][1] = image_url or "å›¾ç‰‡ç”Ÿæˆå¤±è´¥"
        else:
            # è½¬æ¢ä¸ºæœ¬åœ°è·¯å¾„é¿å…SSRFé”™è¯¯
            local_path = url_to_local_path(image_url)
            print(f"DEBUG - åŸå§‹URL: {image_url}")
            print(f"DEBUG - è½¬æ¢åè·¯å¾„: {local_path}")
            print(f"DEBUG - æ–‡ä»¶æ˜¯å¦å­˜åœ¨: {os.path.exists(local_path)}")
            history[-1][1] = (local_path,)
        
        write_debug_info(messages, history)

        yield history
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯ç½‘ç»œæœç´¢æŒ‡ä»¤
    elif last_message.startswith("/search "):
        search_content = last_message[8:]
        
        combined_content = search(search_content)
        messages[-1]["content"] = combined_content
        
        # ä½¿ç”¨ä¿®å‰ªåçš„æ¶ˆæ¯é¿å…ä¸Šä¸‹æ–‡è¿‡é•¿
        trimmed_messages = trim_messages(messages)
        
        response = ""
        new_history = history
        for chunk in chat(trimmed_messages):
            if chunk and chunk.strip():
                response += chunk
                new_history = history[:-1] + [(history[-1][0], response)]
                yield new_history
        
        if response.strip():
            messages.append({"role": "assistant", "content": response.strip()})
        
        write_debug_info(messages, new_history)
    elif current_file_text and current_file_type == '.txt' and last_message == "Please summarize the uploaded document":
        try:
            from pdf import generate_summary, generate_text
            
            summary_prompt = generate_summary(current_file_text)
            print(f"æ€»ç»“æç¤º: {summary_prompt[:100]}...")  # è°ƒè¯•è¾“å‡º
            
            response = ""
            new_history = history
            for chunk in generate_text(summary_prompt):
                if chunk:
                    response += chunk
                    new_history = history[:-1] + [(history[-1][0], response)]
                    yield new_history
            
            if response.strip():
                messages.append({"role": "assistant", "content": response.strip()})
            else:
                error_msg = "æœªèƒ½ç”Ÿæˆæ€»ç»“å†…å®¹xx"
                messages.append({"role": "assistant", "content": error_msg})
                new_history = history[:-1] + [(history[-1][0], error_msg)]
                yield new_history
            
            write_debug_info(messages, new_history)
        
        except Exception as e:
            error_msg = f"æ€»ç»“ç”Ÿæˆé”™è¯¯: {str(e)}"
            messages.append({"role": "assistant", "content": error_msg})
            history[-1][1] = error_msg
            write_debug_info(messages, history)
            yield history
    
    # å¤„ç†/fileæŒ‡ä»¤
    elif last_message.startswith("/file "):
        content = last_message[6:].strip()
        from pdf import generate_question, generate_text
        
        if not current_file_text:
            response = "é”™è¯¯ï¼šè¯·å…ˆä¸Šä¼ æ–‡ä»¶"
            messages.append({"role": "assistant", "content": response})
            history[-1][1] = response
            write_debug_info(messages, history)
            yield history
            return
        
        # ç”Ÿæˆé—®é¢˜æç¤º
        question = generate_question(current_file_text, content)
        messages[-1]["content"] = question
        
        # æµå¼ç”Ÿæˆå›ç­”
        response = ""
        new_history = history
        for chunk in generate_text(question):
            if chunk:
                response += chunk
                new_history = history[:-1] + [(history[-1][0], response)]
                yield new_history
        
        if response.strip():
            messages.append({"role": "assistant", "content": response.strip()})
        
        write_debug_info(messages, new_history)
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯ç½‘é¡µæ€»ç»“æŒ‡ä»¤
    elif last_message.startswith("/fetch "):
        url = last_message[7:].strip()
        
        if not url:
            messages.append({"role": "assistant", "content": "é”™è¯¯ï¼šURLä¸èƒ½ä¸ºç©º"})
            history[-1][1] = "é”™è¯¯ï¼šURLä¸èƒ½ä¸ºç©º"
            write_debug_info(messages, history)
            yield history
            return
            
        # è°ƒç”¨fetchå‡½æ•°è·å–æ€»ç»“é—®é¢˜
        question = fetch(url)
        
        # å¦‚æœfetchè¿”å›é”™è¯¯ä¿¡æ¯ï¼Œç›´æ¥æ˜¾ç¤º
        if question.startswith("é”™è¯¯ï¼š"):
            messages.append({"role": "assistant", "content": question})
            history[-1][1] = question
            write_debug_info(messages, history)
            yield history
            return
            
        # æ›´æ–°messages
        messages[-1]["content"] = question
        
        # ä½¿ç”¨ä¿®å‰ªåçš„æ¶ˆæ¯é¿å…ä¸Šä¸‹æ–‡è¿‡é•¿
        trimmed_messages = trim_messages(messages)
        
        response = ""
        new_history = history
        for chunk in chat(trimmed_messages):
            if chunk and chunk.strip():
                response += chunk
                new_history = history[:-1] + [(history[-1][0], response)]
                yield new_history
        
        if response.strip():
            messages.append({"role": "assistant", "content": response.strip()})
        
        write_debug_info(messages, new_history)
    
    # æ­£å¸¸çš„èŠå¤©å“åº”ä»¥åŠæ–‡ä»¶å“åº”
    else:
        # ä½¿ç”¨ä¿®å‰ªåçš„æ¶ˆæ¯é¿å…ä¸Šä¸‹æ–‡è¿‡é•¿
        trimmed_messages = trim_messages(messages)
        
        response = ""
        new_history = history
        # Stream update history, create a new copy to avoid state issues
        for chunk in chat(trimmed_messages):
            # Only add new reply content, avoid repeating previous dialogue
            if chunk and chunk.strip():
                response += chunk
                # Create a new history copy, only update current assistant reply
                new_history = history[:-1] + [(history[-1][0], response)]
                yield new_history
        # After receiving all, update messages, only save the final reply
        if response.strip():
            messages.append({"role": "assistant", "content": response.strip()})
        
        write_debug_info(messages, new_history)

with gr.Blocks() as demo:
    chatbot = gr.Chatbot(
        [],
        elem_id="chatbot",
        avatar_images=(None, os.path.join(os.path.dirname(__file__), "avatar.png"))  
    )
    
    with gr.Row():
        txt = gr.Textbox(
            scale=4,
            show_label=False,
            placeholder="è¾“å…¥æ–‡æœ¬å¹¶æŒ‰å›è½¦ï¼Œæˆ–ä¸Šä¼ æ–‡ä»¶",
            container=False,
        )
        clear_btn = gr.Button('Clear')
        btn = gr.UploadButton("ğŸ“", file_types=["image", "video", "audio", "text", "pdf"])
    
    txt_msg = txt.submit(
        add_text, [chatbot, txt], [chatbot, txt], queue=False
    ).then(
        bot, chatbot, chatbot  
    ).then(
        lambda: gr.update(interactive=True), None, [txt], queue=False  
    )
    

    file_msg = btn.upload(
        add_file, [chatbot, btn], [chatbot], queue=False
    ).then(
        bot, chatbot, chatbot 
    )
    
   
    def clear_all():
        global messages
        messages = []
        return []

    clear_btn.click(
        clear_all,
        None,
        [chatbot],
        queue=False
    )

if __name__ == "__main__":
    demo.queue()
    demo.launch(allowed_paths=["LocalAI"])
