import gradio as gr
import os
from chat import chat  
from pdf import read_file_content, generate_answer
from image_generate import image_generate
from mnist import image_classification  # å¯¼å…¥å›¾ç‰‡åˆ†ç±»å‡½æ•°
from search import search
from fetch import fetch 
messages = [] 
current_file_text = None  

def write_debug_info(messages, history):
    """Write the current messages and history to answer/answer.txt for debugging purposes"""
    # Create answer directory if it doesn't exist
    os.makedirs('answer', exist_ok=True)
    
    with open('answer/answer.txt', 'a', encoding='utf-8') as f:
        f.write("\n----- Messages -----\n")
        for i, message in enumerate(messages):
            f.write(f"[{i}] {message['role']}: {message['content'][:50]}{'...' if len(message['content']) > 50 else ''}\n")
        
        f.write("\n----- History -----\n")
        for i, (user, assistant) in enumerate(history):
            # User content could be either text or file tuple
            if isinstance(user, tuple):
                user_content = f"File: {user[0]}"
            else:
                user_content = user[:50] + ('...' if len(user) > 50 else '')
            
            # Assistant content could be None, text, or image tuple
            if assistant is None:
                assistant_content = "None"
            elif isinstance(assistant, tuple) and len(assistant) == 1:
                assistant_content = f"Image: {assistant[0][:40]}..."
            else:
                assistant_content = str(assistant)[:50] + ('...' if len(str(assistant)) > 50 else '')
                
            f.write(f"[{i}] user: {user_content}\n")
            f.write(f"    assistant: {assistant_content}\n\n")
        
        f.write("-" * 50 + "\n")

def add_text(history, text):
    """Process user input text, update chat history and message list"""
    global messages
    
    history = history + [(text, None)]
    
    messages.append({"role": "user", "content": text})
    return history, gr.update(value="", interactive=False)  # Clear textbox and disable interaction

def add_file(history, file):
    """Process uploaded file, extract content and update display"""
    global messages, current_file_text
    file_path = file.name
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºPNGå›¾ç‰‡
    if file_path.lower().endswith('.png'):

        filename = os.path.basename(file_path)
        messages.append({"role": "user", "content": f"Please classify {filename}"})
        history = history + [((file.name,), None)]
        return history
    else:
        # éPNGæ–‡ä»¶
        current_file_text = read_file_content(file_path)
        if current_file_text:
            prompt = f"I uploaded a document, the content is as follows: {current_file_text}"
            messages.append({"role": "user", "content": prompt})
            history = history + [((file.name,), None)]
        return history

def bot(history):
    """Call the model to generate a reply and update chat history"""
    global messages, current_file_text

    last_message = messages[-1]["content"]
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯åˆ†ç±»å›¾ç‰‡è¯·æ±‚ï¼ˆæ ¼å¼ä¸º"Please classify {filename}"ï¼‰
    if last_message.startswith("Please classify ") and ".png" in last_message:
        # ä»æœ€åä¸€ä¸ªhistoryæ¡ç›®ä¸­è·å–æ–‡ä»¶è·¯å¾„
        if len(history) > 0 and isinstance(history[-1][0], tuple) and len(history[-1][0]) > 0:
            file_path = history[-1][0][0]  # è·å–æ–‡ä»¶è·¯å¾„

            classification_result = image_classification(file_path)
            messages.append({"role": "assistant", "content": classification_result})
            history[-1][1] = classification_result
            
            write_debug_info(messages, history)
            return history
        
    # æ£€æŸ¥æ˜¯å¦æ˜¯å›¾ç‰‡ç”ŸæˆæŒ‡ä»¤
    elif last_message.startswith("/image "):

        image_content = last_message[7:]  # ç§»é™¤"/image "å‰ç¼€

        image_url = image_generate(image_content)
        messages.append({"role": "assistant", "content": image_url})

        # åˆ¤æ–­è¿”å›çš„æ˜¯URLè¿˜æ˜¯é”™è¯¯ä¿¡æ¯
        if image_url.startswith("å›¾ç‰‡ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™"):
            history[-1][1] = image_url
        else:
            history[-1][1] = (image_url,)
        
        write_debug_info(messages, history)

        return history
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯ç½‘ç»œæœç´¢æŒ‡ä»¤
    elif last_message.startswith("/search "):
        search_content = last_message[8:]
        
        combined_content = search(search_content)
        messages[-1]["content"] = combined_content
        
        response = ""
        new_history = history
        for chunk in chat(messages):
            if chunk and chunk.strip():
                response += chunk
                new_history = history[:-1] + [(history[-1][0], response)]
                yield new_history
        
        if response.strip():
            messages.append({"role": "assistant", "content": response.strip()})
        
        write_debug_info(messages, new_history)
        return new_history
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯ç½‘é¡µæ€»ç»“æŒ‡ä»¤
    elif last_message.startswith("/fetch url "):
        url = last_message[10:].strip()
        
        if not url:
            messages.append({"role": "assistant", "content": "é”™è¯¯ï¼šURLä¸èƒ½ä¸ºç©º"})
            history[-1][1] = "é”™è¯¯ï¼šURLä¸èƒ½ä¸ºç©º"
            write_debug_info(messages, history)
            return history
            
        # è°ƒç”¨fetchå‡½æ•°è·å–æ€»ç»“é—®é¢˜
        question = fetch(url)
        
        # å¦‚æœfetchè¿”å›é”™è¯¯ä¿¡æ¯ï¼Œç›´æ¥æ˜¾ç¤º
        if question.startswith("é”™è¯¯ï¼š"):
            messages.append({"role": "assistant", "content": question})
            history[-1][1] = question
            write_debug_info(messages, history)
            return history
            
        # æ›´æ–°messages
        messages[-1]["content"] = question
        
        response = ""
        new_history = history
        for chunk in chat(messages):
            if chunk and chunk.strip():
                response += chunk
                new_history = history[:-1] + [(history[-1][0], response)]
                yield new_history
        
        if response.strip():
            messages.append({"role": "assistant", "content": response.strip()})
        
        write_debug_info(messages, new_history)
        return new_history
    
    # æ­£å¸¸çš„èŠå¤©å“åº”ä»¥åŠæ–‡ä»¶å“åº”
    else:
        response = ""
        new_history = history
        # Stream update history, create a new copy to avoid state issues
        for chunk in chat(messages):
            # Only add new reply content, avoid repeating previous dialogue
            if chunk and chunk.strip():
                response += chunk
                # Create a new history copy, only update current assistant reply
                new_history = history[:-1] + [(history[-1][0], response)]
                yield new_history
        # After receiving all, update messages, only save the final reply
        if response.strip():
            messages.append({"role": "assistant", "content": response.strip()})
        
        write_debug_info(messages, new_history)

        return new_history

with gr.Blocks() as demo:
    chatbot = gr.Chatbot(
        [],
        elem_id="chatbot",
        avatar_images=(None, os.path.join(os.path.dirname(__file__), "avatar.png"))  
    )
    
    with gr.Row():
        txt = gr.Textbox(
            scale=4,
            show_label=False,
            placeholder="è¾“å…¥æ–‡æœ¬å¹¶æŒ‰å›è½¦ï¼Œæˆ–ä¸Šä¼ æ–‡ä»¶",
            container=False,
        )
        clear_btn = gr.Button('Clear')
        btn = gr.UploadButton("ğŸ“", file_types=["image", "video", "audio", "text", "pdf"])
    
    txt_msg = txt.submit(
        add_text, [chatbot, txt], [chatbot, txt], queue=False
    ).then(
        bot, chatbot, chatbot  
    ).then(
        lambda: gr.update(interactive=True), None, [txt], queue=False  
    )
    

    file_msg = btn.upload(
        add_file, [chatbot, btn], [chatbot], queue=False
    ).then(
        bot, chatbot, chatbot 
    )
    
   
    def clear_all():
        global messages
        messages = []
        return []

    clear_btn.click(
        clear_all,
        None,
        [chatbot],
        queue=False
    )

if __name__ == "__main__":
    demo.queue()
    demo.launch()
